{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn to rank on top of Azure Cognitive Search\n",
    "\n",
    "This notebook showcases how to train an L2 ranker, using a [Learn to rank](https://en.wikipedia.org/wiki/Learning_to_rank) approach, to be run on top of Azure Cognitive Search. \n",
    "\n",
    "Through this experiment, we are going to:\n",
    "1. Use Azure Cognitive Search's new feature computation capability to extract text-based similarity features that describe query-to-document relationships\n",
    "2. Do additional feature engineering to enhance our dataset further \n",
    "2. Train a model using [XGBOOST](https://xgboost.readthedocs.io/en/latest/)\n",
    "3. Evaluate the ranking produced by the trained model against the base Azure Cognitive Search ranking using the [NDCG metric](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext memory_profiler\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "import azs_helpers.l2r_helper as azs\n",
    "\n",
    "from azs_helpers.azure_search_client import azure_search_client as azs_client \n",
    "from azs_helpers.azs_msft_docs import azs_msft_docs as azs_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "\n",
    "This experiment uses a dataset containing **7102 articles** from the **docs.microsoft.com** website. Each article contains a title, body, description, list of api names and a url path. Articles were augmented using the [key phrase extraction cognitive skill](https://docs.microsoft.com/en-us/azure/search/cognitive-search-skill-keyphrases) as well as with popular search terms that led to those articles. Additionally, we augmented the articles with easy to compute metadata that will be leveraged when training, such as the number of sections and tables in each article, as well as the normalized page views count.\n",
    "\n",
    "You can find the full index definition : `azs_helpers\\index_schema\\docs-multilingual-20200217.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"docs-multilingual-20200217\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"id\",\n",
    "      \"type\": \"Edm.String\",\n",
    "      \"facetable\": true,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "The experiment also relies on a labeled training set containing over 900 unique queries evaluated against various articles. We refer to this data as the \"judgment\" list, which will be used as the ground truth when evaluating ranking. Each query is evaluated against 1 to 10 different documents, and for each, provides a \"grade\" representing how relevant that specific document is to that query. A value of 10 indicates high relevance, while a value of 1 indicates lower relevance.\n",
    "\n",
    "The judgement list can be found here: `PATH_TO_JUDGEMENT_LIST.CSV`\n",
    "\n",
    "#### Configuration\n",
    "Details and secrets about your search service should be added to a 'config.json' file of this format:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"service_name\": \"YOUR_SERVICE_NAME\",\n",
    "   \"endpoint\": \"https://YOUR_SERVICE_NAME.search.windows.net\",\n",
    "   \"api_version\": \"2019-05-06-preview\",\n",
    "   \"api_key\": \"YOUR_API_KEY\",\n",
    "   \"index_name\": \"rankingindex-msft-docs\"\n",
    "}\n",
    "```   \n",
    "\n",
    "The 'config.json' file should be placed in the `config` folder within the repository. If you prefer, you can instead uncomment & fill in the cell below, and it'll generate a service config for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure search service configuration. You can uncomment the code here \n",
    "# and fill in the details if you prefer.\n",
    "\n",
    "# service_config = {\n",
    "#     \"serivce_name\": <Your Azure Search Service Name>,\n",
    "#     \"endpoint\": <YOUR ENDPOINT HERE>,\n",
    "#     \"api_version\": \"2019-05-06-preview\",\n",
    "#     \"api_key\": <YOUR API KEY HERE>,\n",
    "#     \"index_name\": â€œdocs-multilingual-20200217\"\n",
    "# }\n",
    "\n",
    "# service_config_root = Path.cwd() / 'config'\n",
    "# service_config_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# service_config_path = service_config_root / 'config.json'\n",
    "# with open(service_config_path, 'w') as f:\n",
    "#     json.dump(service_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_config = {\n",
    "    \"dataset_seed\": 42,\n",
    "    \"verbose\": False,\n",
    "    \"reindex\": False,\n",
    "    \"min_document_count\": 7102,\n",
    "    # Documents path is hardcoded, please change this to your local dir.\n",
    "    \"local_documents_directory_path\" : Path(\"D:/ranking/doc/extracted_ndcg_light\"),\n",
    "    \"judgement_file_path\": Path.cwd() / 'data' / 'raw' / 'msft_docs_labels.csv',\n",
    "    \"service_metadata_config_path\": Path.cwd() / 'config' / 'config.json'\n",
    "}\n",
    "\n",
    "azs_service = azs_client.from_json(local_config['service_metadata_config_path'])\n",
    "msft_docs = azs_docs(local_config['judgement_file_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service preparation\n",
    "The following section is meant to setup an index with the required data to run the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/homeuser/anaconda3/envs/azs-l2r/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'azszorl.eastus.cloudapp.azure.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully connected to search service 'azslearntorank'\n",
      "Index docs-multilingual-20200217 already exists. Skipping creation.\n",
      "Index docs-multilingual-20200217 contains all 7102 documents. Skipping uploading.\n"
     ]
    }
   ],
   "source": [
    "if not azs_service.index_exist():\n",
    "    print(f\"Index {azs_service.index_name} does not exist in service. Creating.\")\n",
    "    index = msft_docs.create_index(azs_service, schema_file=\"docs-multilingual-20200217.json\")\n",
    "else:\n",
    "    print(f\"Index {azs_service.index_name} already exists. Skipping creation.\")\n",
    "    \n",
    "doc_count = azs_service.index_documents_count()\n",
    "if doc_count < local_config[\"min_document_count\"]: \n",
    "    print(f\"Index {azs_service.index_name} contains only {doc_count} out of {local_config['min_document_count']} documents. Uploading documents.\")\n",
    "    docs = msft_docs.get_documents_from_local_folder(local_config[\"local_documents_directory_path\"])\n",
    "    azs_service.upload_documents(docs, 100)\n",
    "else:\n",
    "    print(f\"Index {azs_service.index_name} contains all {doc_count} documents. Skipping uploading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from search service\n",
    "\n",
    "The following functions are designed to efficiently use the Azure Search service to extract document-query features.\n",
    "\n",
    "1. We filter each queries to only consider the documents we want to judge. This is achieved by adding a **\"filter\"** clause to our search query which will restrict the results to the group of documents contained in the group of documents we have judgment values for.\n",
    "2. We set **\"featuresMode\"** to \"enabled\". This will tell the search service to return additional features with the results, including per-field similarity scores.\n",
    "3. We use the **\"select\"** clause to only return the url of each documents, as well as a few non-text based fields that could potentially be used as features. This will greatly reduce the amount of data that needs to be transfered between the server and the client.\n",
    "4. We use the **\"searchFields\"** parameter to select which text-based fields we want to include in the search process. Those fields will be the only ones for which the service will extract text-based features from (such as per-field similarity).\n",
    "\n",
    "The expect response to this query will have the following format:\n",
    "\n",
    "```json\n",
    "    \"value\": [\n",
    "     {\n",
    "        \"@search.score\": 5.1958685,\n",
    "        \"@search.features\": {\n",
    "            \"description_en_us\": {\n",
    "                \"uniqueTokenMatches\": 1.0,\n",
    "                \"similarityScore\": 0.29541412\n",
    "            },\n",
    "            \"body_en_us\": {\n",
    "                \"uniqueTokenMatches\": 3.0,\n",
    "                \"similarityScore\": 0.36644348400000004\n",
    "            },\n",
    "            \"keyPhrases_en_us\": {\n",
    "                \"uniqueTokenMatches\": 3.0,\n",
    "                \"similarityScore\": 0.35014877\n",
    "            },\n",
    "            \"title_en_us\": {\n",
    "                \"uniqueTokenMatches\": 3.0,\n",
    "                \"similarityScore\": 1.75451557\n",
    "            },\n",
    "            \"urlPath\": {\n",
    "                \"uniqueTokenMatches\": 2.0,\n",
    "                \"similarityScore\": 1.07175103\n",
    "            },\n",
    "            \"searchTerms\": {\n",
    "                \"uniqueTokenMatches\": 3.0,\n",
    "                \"similarityScore\": 1.3575956200000001\n",
    "            }\n",
    "        },\n",
    "        \"normalized_pageview\": null,\n",
    "        \"tableCount\": 0,\n",
    "        \"sectionCount\": 7,\n",
    "        \"url_en_us\": \"https://docs.microsoft.com/en-us/azure/search/\"\n",
    "    }]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_search_results_from_service(service, query, urls_filter):\n",
    "    search_request_body = {\n",
    "        \"search\":azs.escape_query(query),\n",
    "        \"featuresMode\": \"enabled\",\n",
    "        \"select\": \"title_en_us, url_en_us, sectionCount, tableCount, normalized_pageview\", \n",
    "        \"searchFields\": \"body_en_us,description_en_us,title_en_us,apiNames,urlPath,searchTerms, keyPhrases_en_us\",\n",
    "        \"scoringStatistics\": \"global\",\n",
    "        \"sessionId\" : \"my_session\",\n",
    "        \"top\" : 20\n",
    "    }\n",
    "    if len(urls_filter) > 0:\n",
    "        search_request_body[\"filter\"] = \" or \".join(f\"url_en_us eq '{url}'\" for url in urls_filter)\n",
    "\n",
    "    return service.search(search_request_body)\n",
    "\n",
    "def get_features_from_service(service, query, group):\n",
    "    urls = group['url'].values.tolist()\n",
    "    \n",
    "    search_results = get_search_results_from_service(service, query, urls)\n",
    "\n",
    "    # this will flatten the search json response into a panda dataframe\n",
    "    azs_features = pd.json_normalize(search_results)\n",
    "    \n",
    "    # we add the data extracted from azure search to our labeled data by merging them on the \"url\" field\n",
    "    merged_results = group.join(azs_features.set_index('url_en_us'), on='url')\n",
    "    \n",
    "    # some of the labeled documents in our dataset did not match any documents in the Azure Search instance,\n",
    "    # we will remove them from our data by dropping any row that did not produce a search score\n",
    "    return merged_results.dropna(subset=['@search.score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make parallel calls to the Azure Search service to extract features\n",
    "\n",
    "To extract all the features from our dataset, we start by grouping the judgment list by query. This will provide us with a list of judged documents for each query. Each call to the Azure Cognitive Search service will use the query from the group,  with filters to make sure we only return the documents from the group. In this dataset, we can expect aproximately 900 queries.\n",
    "\n",
    "To quickly execute those queries, we setup a thread pool executor which will run the queries in parallel. The level of parallelism can be changed to accomodate different search service capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-20 17:25:35\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 2\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 1\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 2\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "Search request failed with status: 503. Sleeping 100ms. Retrying... Retry count so far 0\n",
      "2020-04-20 17:26:26\n"
     ]
    }
   ],
   "source": [
    "import concurrent\n",
    "import datetime\n",
    "from itertools import chain\n",
    "\n",
    "query_groups = msft_docs.judgements.groupby('query')\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(30)\n",
    "futures = [executor.submit(get_features_from_service, azs_service, query, group) for (query, group) in query_groups]\n",
    "concurrent.futures.wait(futures)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "all_features = pd.concat([future.result() for future in futures if future], sort=False).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize data for next step\n",
    "\n",
    "Now that we've successfully processed our dataset, we're going to serialize it to disk for the next part of our tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_data_dir = Path.cwd() / 'data' / 'interim'\n",
    "interim_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_features.to_pickle(interim_data_dir / 'features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
